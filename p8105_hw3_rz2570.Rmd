---
title: "p8105_hw3_rz2570"
author: "Ruilian Zhang"
date: "10/12/2021"
output: github_document
---

```{r}
library(tidyverse)
library(p8105.datasets)

# Set plot options.

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


# Problem 1

```{r}
# Import data and do some exploration.

data("instacart")

dim(instacart)

names(instacart)

head(instacart) 
```

* The `instacart` dataframe has `r ncol(instacart)` of columns and `r nrow(instacart)` of observations. Each row contains relative information of an item from one order , which are: `r names(instacart)`.  
* For example, for product `49302`, its order of being added to cart was `1` by user `112108`, and it's from `dairy eggs` department.  

```{r}
# How many aisles are there, and which aisles are the most items ordered from?

ins_aisle = instacart %>% 
  group_by(aisle) %>% 
  summarize(
    n_obs = n()) %>% 
  arrange(-n_obs)
```

* There are `r nrow(ins_aisle)` aisles, the `fresh vegetables` (`aisle_id` is 83) aisle is the most items are ordered from.

```{r}
# Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered.

ins_aisle %>% 
  filter(n_obs > 10000) %>% 
  mutate(aisle = forcats::fct_reorder(aisle, n_obs)) %>% 
  ggplot(aes(x = aisle, y = n_obs)) +
  geom_bar(stat = "identity", fill = "blue", alpha = .8) +
  coord_flip() +
  labs(
    title = "The number of items ordered in each aisle",
    x = "Aisle",
    y = "Number of items"
  )
```

```{r}
# Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.

popular_items_table = instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  summarize(order_times = n())

knitr::kable(popular_items_table)
```

```{r, warning = FALSE}
# Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

mean_hour_table = instacart %>% 
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(names_from = order_dow,
              values_from = mean_hour) 

knitr::kable(mean_hour_table)
```



# Problem 2

```{r}
# load BRFSS data and do some cleaning

data("brfss_smart2010")

brfss_smart2010 = janitor::clean_names(brfss_smart2010) %>% 
  rename(state = locationabbr) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = factor(response)) %>% 
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  arrange(response)
```

```{r}
# In 2002, which states were observed at 7 or more locations? What about in 2010?

loc_num_2002 = brfss_smart2010 %>% 
  filter(year == "2002") %>% 
  group_by(state) %>% 
  summarize(locations_number = n()) %>% 
  filter(locations_number >= 7)

# What about in 2010?

loc_num_2010 = brfss_smart2010 %>% 
  filter(year == "2010") %>% 
  group_by(state) %>% 
  summarize(locations_number = n()) %>% 
  filter(locations_number >= 7)
```

* In 2002, `r pull(loc_num_2002, state)` were observed at 7 or more locations.  
* In 2010, `r pull(loc_num_2010, state)` were observed at 7 or more locations. 

```{r}
# Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state.

brfss_excellent = brfss_smart2010 %>% 
  filter(response == "Excellent") %>% 
  select(year, state, locationdesc, data_value) %>% 
  drop_na() %>% 
  group_by(year, state) %>% 
  mutate(mean_value = mean(data_value))

# Make a “spaghetti” plot of this average value over time within a state.

brfss_excellent_plot = ggplot(brfss_excellent, aes(x = year, y = mean_value)) +
  geom_line(aes(group = state, color = state)) +
  labs(
    title = "Average value over time within a state",
    x = "Year",
    y = "Average value"
  ) +
  theme(legend.position = "none")

brfss_excellent_plot
```

```{r}
# Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

brfss_ny = brfss_smart2010 %>% 
  filter(year == c("2006", "2010"), state == "NY") %>% 
  group_by(response, locationdesc) %>% 
  separate(locationdesc, into = c("state_prefix", "location"), 5) %>% 
  select(-state_prefix)

brfss_ny_plot = ggplot(brfss_ny, aes(x = location, y = data_value)) +
  geom_point(aes(group = response, color = response)) + 
  coord_flip() +
  facet_grid(. ~ year) +
  labs(
    title = "Distribution of value in New York state",
    x = "Locations",
    y = "Value"
  )
  
brfss_ny_plot
```



# Problem 3

```{r}
# Import and clean accel_data.csv.

accel = read_csv("data/accel_data.csv") %>% 
  janitor::clean_names()

accel = 
  mutate(accel, day = factor(day)) %>% 
  mutate(weekday_vs_weekend = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday")) %>% 
  mutate(weekday_vs_weekend = factor(weekday_vs_weekend)) %>% 
  relocate(week, day_id, day, weekday_vs_weekend)
```

* There are `r nrow(accel)` observations and `r ncol(accel)` variables in `accel` dataset. The variable names are: `week`, `day_id`, `day`, `weekday_vs_weekend` and `activity.*`. Among them, variables `activity.*` are the activity counts for each minute of a 24-hour day starting at midnight.

```{r}
# Aggregate across minutes to create a total activity variable for each day, and create a table showing these totals.

# accel = mutate(accel, total_activity = rowSums(accel[ ,[5:1444]]))

accel_sub = accel[ , 5:1444]

day_sum = rowSums(accel_sub)

sum_table = as.table(day_sum)
knitr::kable(sum_table)
```

